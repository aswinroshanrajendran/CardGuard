{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a46e321",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - Exploratory Data Analysis\n",
    "\n",
    "## üìÑ About the Dataset\n",
    "\n",
    "This project uses a **simulated credit card transaction dataset** provided on Kaggle. The dataset contains over 550,000 transactions from January 1st, 2019 to December 31st, 2020. These transactions were generated using a simulation tool called **Sparkov** which creates realistic behavioral patterns based on profiles such as age, gender, and location.\n",
    "\n",
    "The goal is to analyze the dataset and identify key patterns that distinguish **fraudulent transactions (`is_fraud = 1`)** from **legitimate ones (`is_fraud = 0`)**.\n",
    "\n",
    "You can find the dataset [here](https://www.kaggle.com/datasets/kartik2112/fraud-detection?select=fraudTrain.csv).\n",
    "\n",
    "### üí° Dataset Details:\n",
    "\n",
    "The dataset includes:\n",
    "\n",
    "- **Demographic information** (e.g., name, gender, job, DOB)\n",
    "- **Transaction details** (amount, category, merchant)\n",
    "- **Geolocation** (latitude, longitude)\n",
    "- **Temporal features** (transaction timestamp)\n",
    "- **Label**: `is_fraud` (target class)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Note:\n",
    "\n",
    "We are using only the `fraudTrain.csv` file as our base dataset. This file contains both fraud and legitimate transactions. We'll later perform our own **train-test split** to ensure consistent preprocessing and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a6ac5",
   "metadata": {},
   "source": [
    "### üß† Credit Card Fraud Detection ‚Äì Exploratory Data Analysis (EDA)\n",
    "This notebook focuses on exploring a simulated credit card transactions dataset to detect patterns and insights related to fraudulent behavior. We aim to understand the data through statistical summaries, visualizations, and correlations before building any models.\n",
    "\n",
    "Source: Kaggle Dataset - Credit Card Fraud Detection\n",
    "\n",
    "Dataset Used: fraudTrain.csv\n",
    "\n",
    "Objective: Understand the structure and patterns in data to prepare it for modeling fraudulent vs. legitimate transactions (is_fraud target class).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00615863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19fe509",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Load and View the Dataset\n",
    "We begin by loading the fraudTrain.csv file to examine its structure and check for basic information like number of rows, columns, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6881fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (1296675, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "0           0   2019-01-01 00:00:18  2703186189652095   \n",
       "1           1   2019-01-01 00:00:44      630423337322   \n",
       "2           2   2019-01-01 00:00:51    38859492057661   \n",
       "3           3   2019-01-01 00:01:16  3534093764340240   \n",
       "4           4   2019-01-01 00:03:06   375534208663984   \n",
       "\n",
       "                             merchant       category     amt      first  \\\n",
       "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
       "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
       "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
       "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
       "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
       "\n",
       "      last gender                        street  ...      lat      long  \\\n",
       "0    Banks      F                561 Perry Cove  ...  36.0788  -81.1781   \n",
       "1     Gill      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105   \n",
       "2  Sanchez      M      594 White Dale Suite 530  ...  42.1808 -112.2620   \n",
       "3    White      M   9443 Cynthia Court Apt. 038  ...  46.2306 -112.1138   \n",
       "4   Garcia      M              408 Bradley Rest  ...  38.4207  -79.4629   \n",
       "\n",
       "   city_pop                                job         dob  \\\n",
       "0      3495          Psychologist, counselling  1988-03-09   \n",
       "1       149  Special educational needs teacher  1978-06-21   \n",
       "2      4154        Nature conservation officer  1962-01-19   \n",
       "3      1939                    Patent attorney  1967-01-12   \n",
       "4        99     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\aswin\\Downloads\\fraudTrain.csv\")\n",
    "\n",
    "# Display the shape and first few rows\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e400c2",
   "metadata": {},
   "source": [
    "### üîç Initial Overview\n",
    "Let's use .info() and .describe() to get a sense of the dataset‚Äôs structure and summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fb00ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1296675 non-null  int64  \n",
      " 1   trans_date_trans_time  1296675 non-null  object \n",
      " 2   cc_num                 1296675 non-null  int64  \n",
      " 3   merchant               1296675 non-null  object \n",
      " 4   category               1296675 non-null  object \n",
      " 5   amt                    1296675 non-null  float64\n",
      " 6   first                  1296675 non-null  object \n",
      " 7   last                   1296675 non-null  object \n",
      " 8   gender                 1296675 non-null  object \n",
      " 9   street                 1296675 non-null  object \n",
      " 10  city                   1296675 non-null  object \n",
      " 11  state                  1296675 non-null  object \n",
      " 12  zip                    1296675 non-null  int64  \n",
      " 13  lat                    1296675 non-null  float64\n",
      " 14  long                   1296675 non-null  float64\n",
      " 15  city_pop               1296675 non-null  int64  \n",
      " 16  job                    1296675 non-null  object \n",
      " 17  dob                    1296675 non-null  object \n",
      " 18  trans_num              1296675 non-null  object \n",
      " 19  unix_time              1296675 non-null  int64  \n",
      " 20  merch_lat              1296675 non-null  float64\n",
      " 21  merch_long             1296675 non-null  float64\n",
      " 22  is_fraud               1296675 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 227.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Data info\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff3d471",
   "metadata": {},
   "source": [
    "### üßπ Drop Unnecessary Columns\n",
    "The Unnamed: 0 column is simply a duplicate index and doesn‚Äôt add analytical value. We will remove it to keep the dataset clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b3cff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of dataset: (1296675, 22)\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'Unnamed: 0' column\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Confirm the new shape\n",
    "print(\"New shape of dataset:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adee331",
   "metadata": {},
   "source": [
    "### üîç Check for Duplicate Rows\n",
    "It‚Äôs important to identify and remove any duplicate transactions that might skew the analysis or model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0905dc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "No duplicates found.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Optionally, drop duplicates if any found\n",
    "if duplicates > 0:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"Duplicates removed. New shape: {df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23be3799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans_date_trans_time    datetime64[ns]\n",
      "dob                      datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert 'trans_date_trans_time' and 'dob' to datetime\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "\n",
    "# Confirm the changes\n",
    "print(df[['trans_date_trans_time', 'dob']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c58433b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num                            merchant  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
       "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
       "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
       "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
       "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
       "\n",
       "        category     amt      first     last gender  \\\n",
       "0       misc_net    4.97   Jennifer    Banks      F   \n",
       "1    grocery_pos  107.23  Stephanie     Gill      F   \n",
       "2  entertainment  220.11     Edward  Sanchez      M   \n",
       "3  gas_transport   45.00     Jeremy    White      M   \n",
       "4       misc_pos   41.96      Tyler   Garcia      M   \n",
       "\n",
       "                         street            city  ...      lat      long  \\\n",
       "0                561 Perry Cove  Moravian Falls  ...  36.0788  -81.1781   \n",
       "1  43039 Riley Greens Suite 393          Orient  ...  48.8878 -118.2105   \n",
       "2      594 White Dale Suite 530      Malad City  ...  42.1808 -112.2620   \n",
       "3   9443 Cynthia Court Apt. 038         Boulder  ...  46.2306 -112.1138   \n",
       "4              408 Bradley Rest        Doe Hill  ...  38.4207  -79.4629   \n",
       "\n",
       "   city_pop                                job        dob  \\\n",
       "0      3495          Psychologist, counselling 1988-03-09   \n",
       "1       149  Special educational needs teacher 1978-06-21   \n",
       "2      4154        Nature conservation officer 1962-01-19   \n",
       "3      1939                    Patent attorney 1967-01-12   \n",
       "4        99     Dance movement psychotherapist 1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8352e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from transaction datetime\n",
    "df['trans_year'] = df['trans_date_trans_time'].dt.year\n",
    "df['trans_month'] = df['trans_date_trans_time'].dt.month\n",
    "df['trans_day'] = df['trans_date_trans_time'].dt.day\n",
    "df['trans_hour'] = df['trans_date_trans_time'].dt.hour\n",
    "df['trans_day_of_week'] = df['trans_date_trans_time'].dt.dayofweek  # Monday=0, Sunday=6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d7b74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age at the time of transaction\n",
    "df['age'] = (df['trans_date_trans_time'] - df['dob']).dt.days // 365\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f260b93c",
   "metadata": {},
   "source": [
    "### Check for Missing Values\n",
    "We need to inspect whether any columns have missing (NaN) values. This helps us decide if imputation or column dropping is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "471488e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No missing values found.\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "if missing_values.empty:\n",
    "    print(\"‚úÖ No missing values found.\")\n",
    "else:\n",
    "    print(\"‚ùå Columns with missing values:\\n\")\n",
    "    print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d907025",
   "metadata": {},
   "source": [
    "### Basic Statistical Summary & Class Balance\n",
    "\n",
    "Before diving into visualizations, let‚Äôs:\n",
    "\n",
    "Get a statistical summary of numerical columns.\n",
    "\n",
    "Check the balance of our target class (is_fraud) to understand if the dataset is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a277ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Class Distribution:\n",
      "0    1289169\n",
      "1       7506\n",
      "Name: is_fraud, dtype: int64\n",
      "\n",
      "Percentage Distribution:\n",
      "0    99.421135\n",
      "1     0.578865\n",
      "Name: is_fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Statistical summary of numerical features\n",
    "df.describe()\n",
    "\n",
    "# Distribution of target variable\n",
    "fraud_counts = df['is_fraud'].value_counts()\n",
    "fraud_percent = df['is_fraud'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Fraud Class Distribution:\")\n",
    "print(fraud_counts)\n",
    "print(\"\\nPercentage Distribution:\")\n",
    "print(fraud_percent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064fbfbd",
   "metadata": {},
   "source": [
    "Class 0 (Not Fraud): ~99.42%\n",
    "\n",
    "Class 1 (Fraud): ~0.58%\n",
    "\n",
    "This imbalance will strongly influence model performance. If we don't address it, the model might just predict ‚ÄúNot Fraud‚Äù every time and still get high accuracy ‚Äî but it will fail to detect actual frauds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4667b",
   "metadata": {},
   "source": [
    "### Check Cardinality of Categorical Columns\n",
    "Next, let's look at how many unique values exist in the categorical columns (like merchant, job, category, etc.). This helps us understand which ones are useful or too sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f7cb196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant: 693 unique values\n",
      "category: 14 unique values\n",
      "first: 352 unique values\n",
      "last: 481 unique values\n",
      "gender: 2 unique values\n",
      "street: 983 unique values\n",
      "city: 894 unique values\n",
      "state: 51 unique values\n",
      "job: 494 unique values\n",
      "trans_num: 1296675 unique values\n"
     ]
    }
   ],
   "source": [
    "# Select object (categorical) columns\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "# Unique values in each categorical column\n",
    "for col in cat_cols:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3c211da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>amt</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>trans_year</th>\n",
       "      <th>trans_month</th>\n",
       "      <th>trans_day</th>\n",
       "      <th>trans_hour</th>\n",
       "      <th>trans_day_of_week</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.171920e+17</td>\n",
       "      <td>7.035104e+01</td>\n",
       "      <td>4.880067e+04</td>\n",
       "      <td>3.853762e+01</td>\n",
       "      <td>-9.022634e+01</td>\n",
       "      <td>8.882444e+04</td>\n",
       "      <td>1.349244e+09</td>\n",
       "      <td>3.853734e+01</td>\n",
       "      <td>-9.022646e+01</td>\n",
       "      <td>5.788652e-03</td>\n",
       "      <td>2.019287e+03</td>\n",
       "      <td>6.142150e+00</td>\n",
       "      <td>1.558798e+01</td>\n",
       "      <td>1.280486e+01</td>\n",
       "      <td>3.070604e+00</td>\n",
       "      <td>4.552822e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.308806e+18</td>\n",
       "      <td>1.603160e+02</td>\n",
       "      <td>2.689322e+04</td>\n",
       "      <td>5.075808e+00</td>\n",
       "      <td>1.375908e+01</td>\n",
       "      <td>3.019564e+05</td>\n",
       "      <td>1.284128e+07</td>\n",
       "      <td>5.109788e+00</td>\n",
       "      <td>1.377109e+01</td>\n",
       "      <td>7.586269e-02</td>\n",
       "      <td>4.522452e-01</td>\n",
       "      <td>3.417703e+00</td>\n",
       "      <td>8.829121e+00</td>\n",
       "      <td>6.817824e+00</td>\n",
       "      <td>2.198153e+00</td>\n",
       "      <td>1.740895e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.041621e+10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.257000e+03</td>\n",
       "      <td>2.002710e+01</td>\n",
       "      <td>-1.656723e+02</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.325376e+09</td>\n",
       "      <td>1.902779e+01</td>\n",
       "      <td>-1.666712e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.019000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.800429e+14</td>\n",
       "      <td>9.650000e+00</td>\n",
       "      <td>2.623700e+04</td>\n",
       "      <td>3.462050e+01</td>\n",
       "      <td>-9.679800e+01</td>\n",
       "      <td>7.430000e+02</td>\n",
       "      <td>1.338751e+09</td>\n",
       "      <td>3.473357e+01</td>\n",
       "      <td>-9.689728e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.019000e+03</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.521417e+15</td>\n",
       "      <td>4.752000e+01</td>\n",
       "      <td>4.817400e+04</td>\n",
       "      <td>3.935430e+01</td>\n",
       "      <td>-8.747690e+01</td>\n",
       "      <td>2.456000e+03</td>\n",
       "      <td>1.349250e+09</td>\n",
       "      <td>3.936568e+01</td>\n",
       "      <td>-8.743839e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.019000e+03</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.642255e+15</td>\n",
       "      <td>8.314000e+01</td>\n",
       "      <td>7.204200e+04</td>\n",
       "      <td>4.194040e+01</td>\n",
       "      <td>-8.015800e+01</td>\n",
       "      <td>2.032800e+04</td>\n",
       "      <td>1.359385e+09</td>\n",
       "      <td>4.195716e+01</td>\n",
       "      <td>-8.023680e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.020000e+03</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.992346e+18</td>\n",
       "      <td>2.894890e+04</td>\n",
       "      <td>9.978300e+04</td>\n",
       "      <td>6.669330e+01</td>\n",
       "      <td>-6.795030e+01</td>\n",
       "      <td>2.906700e+06</td>\n",
       "      <td>1.371817e+09</td>\n",
       "      <td>6.751027e+01</td>\n",
       "      <td>-6.695090e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.020000e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>9.500000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cc_num           amt           zip           lat          long  \\\n",
       "count  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \n",
       "mean   4.171920e+17  7.035104e+01  4.880067e+04  3.853762e+01 -9.022634e+01   \n",
       "std    1.308806e+18  1.603160e+02  2.689322e+04  5.075808e+00  1.375908e+01   \n",
       "min    6.041621e+10  1.000000e+00  1.257000e+03  2.002710e+01 -1.656723e+02   \n",
       "25%    1.800429e+14  9.650000e+00  2.623700e+04  3.462050e+01 -9.679800e+01   \n",
       "50%    3.521417e+15  4.752000e+01  4.817400e+04  3.935430e+01 -8.747690e+01   \n",
       "75%    4.642255e+15  8.314000e+01  7.204200e+04  4.194040e+01 -8.015800e+01   \n",
       "max    4.992346e+18  2.894890e+04  9.978300e+04  6.669330e+01 -6.795030e+01   \n",
       "\n",
       "           city_pop     unix_time     merch_lat    merch_long      is_fraud  \\\n",
       "count  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \n",
       "mean   8.882444e+04  1.349244e+09  3.853734e+01 -9.022646e+01  5.788652e-03   \n",
       "std    3.019564e+05  1.284128e+07  5.109788e+00  1.377109e+01  7.586269e-02   \n",
       "min    2.300000e+01  1.325376e+09  1.902779e+01 -1.666712e+02  0.000000e+00   \n",
       "25%    7.430000e+02  1.338751e+09  3.473357e+01 -9.689728e+01  0.000000e+00   \n",
       "50%    2.456000e+03  1.349250e+09  3.936568e+01 -8.743839e+01  0.000000e+00   \n",
       "75%    2.032800e+04  1.359385e+09  4.195716e+01 -8.023680e+01  0.000000e+00   \n",
       "max    2.906700e+06  1.371817e+09  6.751027e+01 -6.695090e+01  1.000000e+00   \n",
       "\n",
       "         trans_year   trans_month     trans_day    trans_hour  \\\n",
       "count  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \n",
       "mean   2.019287e+03  6.142150e+00  1.558798e+01  1.280486e+01   \n",
       "std    4.522452e-01  3.417703e+00  8.829121e+00  6.817824e+00   \n",
       "min    2.019000e+03  1.000000e+00  1.000000e+00  0.000000e+00   \n",
       "25%    2.019000e+03  3.000000e+00  8.000000e+00  7.000000e+00   \n",
       "50%    2.019000e+03  6.000000e+00  1.500000e+01  1.400000e+01   \n",
       "75%    2.020000e+03  9.000000e+00  2.300000e+01  1.900000e+01   \n",
       "max    2.020000e+03  1.200000e+01  3.100000e+01  2.300000e+01   \n",
       "\n",
       "       trans_day_of_week           age  \n",
       "count       1.296675e+06  1.296675e+06  \n",
       "mean        3.070604e+00  4.552822e+01  \n",
       "std         2.198153e+00  1.740895e+01  \n",
       "min         0.000000e+00  1.300000e+01  \n",
       "25%         1.000000e+00  3.200000e+01  \n",
       "50%         3.000000e+00  4.400000e+01  \n",
       "75%         5.000000e+00  5.700000e+01  \n",
       "max         6.000000e+00  9.500000e+01  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991c7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['unix_time', 'trans_num', 'first', 'last', 'street'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b194717",
   "metadata": {},
   "source": [
    "### Calculate Distance Between Customer and Merchant\n",
    "We can create a new feature distance using the Haversine formula to calculate the geographical distance between the transaction location and the merchant's location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54ffac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "\n",
    "    a = np.sin(delta_phi / 2.0)**2 + \\\n",
    "        np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# Apply the function\n",
    "df['distance'] = haversine(df['lat'], df['long'], df['merch_lat'], df['merch_long'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6993b1",
   "metadata": {},
   "source": [
    "###  Drop Latitude/Longitude Columns After Distance\n",
    "After calculating distance, the raw coordinates become redundant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e14ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['lat', 'long', 'merch_lat', 'merch_long'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57cd785a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>trans_year</th>\n",
       "      <th>trans_month</th>\n",
       "      <th>trans_day</th>\n",
       "      <th>trans_hour</th>\n",
       "      <th>trans_day_of_week</th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>F</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>NC</td>\n",
       "      <td>28654</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>78.597568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>F</td>\n",
       "      <td>Orient</td>\n",
       "      <td>WA</td>\n",
       "      <td>99160</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>30.212176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>M</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>ID</td>\n",
       "      <td>83252</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>108.206083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>M</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>MT</td>\n",
       "      <td>59632</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>95.673231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>M</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>VA</td>\n",
       "      <td>24433</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>77.556744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num                            merchant  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
       "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
       "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
       "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
       "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
       "\n",
       "        category     amt gender            city state    zip  city_pop  \\\n",
       "0       misc_net    4.97      F  Moravian Falls    NC  28654      3495   \n",
       "1    grocery_pos  107.23      F          Orient    WA  99160       149   \n",
       "2  entertainment  220.11      M      Malad City    ID  83252      4154   \n",
       "3  gas_transport   45.00      M         Boulder    MT  59632      1939   \n",
       "4       misc_pos   41.96      M        Doe Hill    VA  24433        99   \n",
       "\n",
       "                                 job        dob  is_fraud  trans_year  \\\n",
       "0          Psychologist, counselling 1988-03-09         0        2019   \n",
       "1  Special educational needs teacher 1978-06-21         0        2019   \n",
       "2        Nature conservation officer 1962-01-19         0        2019   \n",
       "3                    Patent attorney 1967-01-12         0        2019   \n",
       "4     Dance movement psychotherapist 1986-03-28         0        2019   \n",
       "\n",
       "   trans_month  trans_day  trans_hour  trans_day_of_week  age    distance  \n",
       "0            1          1           0                  1   30   78.597568  \n",
       "1            1          1           0                  1   40   30.212176  \n",
       "2            1          1           0                  1   56  108.206083  \n",
       "3            1          1           0                  1   52   95.673231  \n",
       "4            1          1           0                  1   32   77.556744  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb409c",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f893d714",
   "metadata": {},
   "source": [
    " Identify Categorical Columns\n",
    "From your df.head(), these are the remaining categorical columns:\n",
    "\n",
    "merchant ‚Äì many unique values (you might drop or encode later)\n",
    "\n",
    "category ‚Äì 14 categories ‚Üí good for one-hot encoding\n",
    "\n",
    "gender ‚Äì binary ‚Üí can use label encoding\n",
    "\n",
    "city, state ‚Äì high cardinality ‚Üí can drop for now or encode with care\n",
    "\n",
    "job ‚Äì high cardinality ‚Üí can drop or target encode later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b37cff69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>zip</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>dob</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>trans_year</th>\n",
       "      <th>trans_month</th>\n",
       "      <th>...</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>category_kids_pets</th>\n",
       "      <th>category_misc_net</th>\n",
       "      <th>category_misc_pos</th>\n",
       "      <th>category_personal_care</th>\n",
       "      <th>category_shopping_net</th>\n",
       "      <th>category_shopping_pos</th>\n",
       "      <th>category_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>28654</td>\n",
       "      <td>3495</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>107.23</td>\n",
       "      <td>0</td>\n",
       "      <td>99160</td>\n",
       "      <td>149</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>220.11</td>\n",
       "      <td>1</td>\n",
       "      <td>83252</td>\n",
       "      <td>4154</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>45.00</td>\n",
       "      <td>1</td>\n",
       "      <td>59632</td>\n",
       "      <td>1939</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>41.96</td>\n",
       "      <td>1</td>\n",
       "      <td>24433</td>\n",
       "      <td>99</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num     amt  gender    zip  city_pop  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095    4.97       0  28654      3495   \n",
       "1   2019-01-01 00:00:44      630423337322  107.23       0  99160       149   \n",
       "2   2019-01-01 00:00:51    38859492057661  220.11       1  83252      4154   \n",
       "3   2019-01-01 00:01:16  3534093764340240   45.00       1  59632      1939   \n",
       "4   2019-01-01 00:03:06   375534208663984   41.96       1  24433        99   \n",
       "\n",
       "         dob  is_fraud  trans_year  trans_month  ...  category_grocery_pos  \\\n",
       "0 1988-03-09         0        2019            1  ...                     0   \n",
       "1 1978-06-21         0        2019            1  ...                     1   \n",
       "2 1962-01-19         0        2019            1  ...                     0   \n",
       "3 1967-01-12         0        2019            1  ...                     0   \n",
       "4 1986-03-28         0        2019            1  ...                     0   \n",
       "\n",
       "   category_health_fitness  category_home  category_kids_pets  \\\n",
       "0                        0              0                   0   \n",
       "1                        0              0                   0   \n",
       "2                        0              0                   0   \n",
       "3                        0              0                   0   \n",
       "4                        0              0                   0   \n",
       "\n",
       "   category_misc_net  category_misc_pos  category_personal_care  \\\n",
       "0                  1                  0                       0   \n",
       "1                  0                  0                       0   \n",
       "2                  0                  0                       0   \n",
       "3                  0                  0                       0   \n",
       "4                  0                  1                       0   \n",
       "\n",
       "   category_shopping_net  category_shopping_pos  category_travel  \n",
       "0                      0                      0                0  \n",
       "1                      0                      0                0  \n",
       "2                      0                      0                0  \n",
       "3                      0                      0                0  \n",
       "4                      0                      0                0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encode gender\n",
    "df['gender'] = df['gender'].map({'F': 0, 'M': 1})\n",
    "\n",
    "# One-hot encode category\n",
    "df = pd.get_dummies(df, columns=['category'], drop_first=True)\n",
    "\n",
    "df.drop(['merchant', 'city', 'state', 'job'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922ebe5",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "Before training your machine learning model, you should scale the numerical features. This ensures that models like logistic regression or KNN don‚Äôt get biased by feature magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8e5dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select numerical columns to scale\n",
    "num_cols = ['amt', 'city_pop', 'age', 'distance', 'trans_hour']  # Add other numerical features if present\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0eb418d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trans_date_trans_time', 'cc_num', 'amt', 'gender', 'zip', 'city_pop', 'dob', 'is_fraud', 'trans_year', 'trans_month', 'trans_day', 'trans_hour', 'trans_day_of_week', 'age', 'distance', 'category_food_dining', 'category_gas_transport', 'category_grocery_net', 'category_grocery_pos', 'category_health_fitness', 'category_home', 'category_kids_pets', 'category_misc_net', 'category_misc_pos', 'category_personal_care', 'category_shopping_net', 'category_shopping_pos', 'category_travel']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f5af1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_fraud                   1.000000\n",
      "amt                        0.219404\n",
      "category_shopping_net      0.044261\n",
      "category_grocery_pos       0.035558\n",
      "category_misc_net          0.025886\n",
      "trans_hour                 0.013799\n",
      "age                        0.012244\n",
      "gender                     0.007642\n",
      "category_shopping_pos      0.005955\n",
      "trans_day                  0.003848\n",
      "trans_year                 0.003004\n",
      "city_pop                   0.002136\n",
      "trans_day_of_week          0.001739\n",
      "distance                   0.000403\n",
      "cc_num                    -0.000981\n",
      "zip                       -0.002162\n",
      "category_gas_transport    -0.004851\n",
      "category_travel           -0.006924\n",
      "category_grocery_net      -0.007136\n",
      "category_misc_pos         -0.008937\n",
      "category_personal_care    -0.012167\n",
      "trans_month               -0.012409\n",
      "category_health_fitness   -0.014885\n",
      "category_kids_pets        -0.014967\n",
      "category_food_dining      -0.015025\n",
      "category_home             -0.017848\n",
      "Name: is_fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_with_target = df.corr()['is_fraud'].sort_values(ascending=False)\n",
    "print(corr_with_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b73e8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\n",
    "    'amt',\n",
    "    'age',\n",
    "    'gender',\n",
    "    'trans_hour',\n",
    "    'trans_day_of_week',\n",
    "    'category_grocery_pos',\n",
    "    'category_shopping_net',\n",
    "    'category_misc_net'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "caf201da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df[features_to_keep + ['is_fraud']]  # Keep the target column as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a15d92c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        amt       age  gender  trans_hour  trans_day_of_week  \\\n",
      "0 -0.407826 -0.891968       0   -1.878145                  1   \n",
      "1  0.230039 -0.317551       0   -1.878145                  1   \n",
      "2  0.934149  0.601517       1   -1.878145                  1   \n",
      "3 -0.158132  0.371750       1   -1.878145                  1   \n",
      "4 -0.177094 -0.777085       1   -1.878145                  1   \n",
      "\n",
      "   category_grocery_pos  category_shopping_net  category_misc_net  is_fraud  \n",
      "0                     0                      0                  1         0  \n",
      "1                     1                      0                  0         0  \n",
      "2                     0                      0                  0         0  \n",
      "3                     0                      0                  0         0  \n",
      "4                     0                      0                  0         0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   amt                    1296675 non-null  float64\n",
      " 1   age                    1296675 non-null  float64\n",
      " 2   gender                 1296675 non-null  int64  \n",
      " 3   trans_hour             1296675 non-null  float64\n",
      " 4   trans_day_of_week      1296675 non-null  int64  \n",
      " 5   category_grocery_pos   1296675 non-null  uint8  \n",
      " 6   category_shopping_net  1296675 non-null  uint8  \n",
      " 7   category_misc_net      1296675 non-null  uint8  \n",
      " 8   is_fraud               1296675 non-null  int64  \n",
      "dtypes: float64(3), int64(3), uint8(3)\n",
      "memory usage: 63.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_reduced.head())\n",
    "print(df_reduced.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46ac86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_reduced.drop('is_fraud', axis=1)\n",
    "y = df_reduced['is_fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8303341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    257834\n",
      "           1       0.00      0.00      0.00      1501\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.50      0.50      0.50    259335\n",
      "weighted avg       0.99      0.99      0.99    259335\n",
      "\n",
      "ROC AUC Score: 0.8061825767005618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Initialize model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3854200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: 0    1031335\n",
      "1       6005\n",
      "Name: is_fraud, dtype: int64\n",
      "After SMOTE: 0    1031335\n",
      "1    1031335\n",
      "Name: is_fraud, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97    257834\n",
      "           1       0.07      0.76      0.12      1501\n",
      "\n",
      "    accuracy                           0.94    259335\n",
      "   macro avg       0.53      0.85      0.55    259335\n",
      "weighted avg       0.99      0.94      0.96    259335\n",
      "\n",
      "ROC AUC Score: 0.8489611505870691\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Assume X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "print(\"After SMOTE:\", pd.Series(y_train_res).value_counts())\n",
    "\n",
    "# Train your model (e.g. Logistic Regression)\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model performance\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4657d383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97    257834\n",
      "           1       0.07      0.76      0.12      1501\n",
      "\n",
      "    accuracy                           0.94    259335\n",
      "   macro avg       0.53      0.85      0.55    259335\n",
      "weighted avg       0.99      0.94      0.96    259335\n",
      "\n",
      "ROC AUC Score: 0.8489611505870691\n",
      "\n",
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.48      0.77      0.59      1501\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.74      0.88      0.80    259335\n",
      "weighted avg       1.00      0.99      0.99    259335\n",
      "\n",
      "ROC AUC Score: 0.9708688536034813\n",
      "\n",
      "XGBoost Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    257834\n",
      "           1       0.39      0.82      0.53      1501\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.69      0.91      0.76    259335\n",
      "weighted avg       1.00      0.99      0.99    259335\n",
      "\n",
      "ROC AUC Score: 0.9870420683988831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Logistic Regression (already done)\n",
    "print(\"Logistic Regression Results:\")\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_lr.fit(X_train_res, y_train_res)\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "y_prob_lr = model_lr.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob_lr))\n",
    "\n",
    "# Random Forest\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "model_rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model_rf.fit(X_train_res, y_train_res)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "y_prob_rf = model_rf.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob_rf))\n",
    "\n",
    "# XGBoost\n",
    "print(\"\\nXGBoost Results:\")\n",
    "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model_xgb.fit(X_train_res, y_train_res)\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "y_prob_xgb = model_xgb.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc54d562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best params: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.2, 'colsample_bytree': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    257834\n",
      "           1       0.40      0.83      0.54      1501\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.70      0.91      0.77    259335\n",
      "weighted avg       1.00      0.99      0.99    259335\n",
      "\n",
      "ROC AUC Score: 0.9881731859898578\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Reduce parameter grid or keep as is, but n_iter=10\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 1],\n",
    "    'colsample_bytree': [0.7, 0.8, 1]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,   # fewer iterations\n",
    "    cv=2,        # fewer folds\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit with early stopping on validation set inside cv might be tricky, but RandomizedSearchCV handles it internally\n",
    "random_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Best params:\", random_search.best_params_)\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "y_prob = random_search.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457faffc",
   "metadata": {},
   "source": [
    "‚úÖ ROC AUC Score: 0.988 ‚Äî excellent! It shows your model distinguishes well between fraud and non-fraud.\n",
    "\n",
    "‚úÖ Recall for class 1 (fraud): 0.83 ‚Äî this is strong and crucial for fraud detection (catching actual frauds).\n",
    "\n",
    "‚úÖ F1-score for fraud: 0.54 ‚Äî not perfect, but acceptable considering class imbalance. You can still improve this later if needed.\n",
    "\n",
    "‚úÖ Accuracy: 99% ‚Äî high, but expected due to the dataset being mostly non-fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "626de2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: F:\\Aswin\\01 epita\\Projects\\Data science Portfolio Projects\\Card_Guard\\Card_Guard\\models\\xgboost_fraud_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the path to the models directory\n",
    "model_dir = r\"F:\\Aswin\\01 epita\\Projects\\Data science Portfolio Projects\\Card_Guard\\Card_Guard\\models\"\n",
    "os.makedirs(model_dir, exist_ok=True)  # Ensure the folder exists\n",
    "\n",
    "# Full path to save the model\n",
    "model_path = os.path.join(model_dir, \"xgboost_fraud_model.pkl\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(random_search.best_estimator_, model_path)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e815e8",
   "metadata": {},
   "source": [
    "Load the saved model and use it for prediction:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96b564e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    257834\n",
      "           1       0.40      0.83      0.54      1501\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.70      0.91      0.77    259335\n",
      "weighted avg       1.00      0.99      0.99    259335\n",
      "\n",
      "ROC AUC Score: 0.9881731859898578\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Path to the saved model\n",
    "model_path = r\"F:\\Aswin\\01 epita\\Projects\\Data science Portfolio Projects\\Card_Guard\\Card_Guard\\models\\xgboost_fraud_model.pkl\"\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load(model_path)\n",
    "\n",
    "# Make predictions (example)\n",
    "y_loaded_pred = loaded_model.predict(X_test)\n",
    "y_loaded_prob = loaded_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate to confirm it's working\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "print(\"Loaded Model Evaluation:\")\n",
    "print(classification_report(y_test, y_loaded_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_loaded_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d5122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "card_guard_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
